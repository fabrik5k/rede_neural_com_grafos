# -*- coding: utf-8 -*-
"""Deep_learning_classificador_com_grafo

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UIYVP95A8xCnVJNCOJW7_q0MzjPaIdUZ
"""



"""Instalação dos pacotes e função de visualização"""

# Commented out IPython magic to ensure Python compatibility.
# Instalando pacotes requeridos
import os
import torch
os.environ['TORCH'] = torch.__version__
print(torch.__version__)

!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html
!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html
!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git

# Função que ajuda na visualização
# %matplotlib inline
import networkx as nx
import matplotlib.pyplot as plt


def visualize_graph(G, color):
    plt.figure(figsize=(7,7))
    plt.xticks([])
    plt.yticks([])
    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,
                     node_color=color, cmap="Set2")
    plt.show()


def visualize_embedding(h, color, epoch=None, loss=None):
    plt.figure(figsize=(7,7))
    plt.xticks([])
    plt.yticks([])
    h = h.detach().cpu().numpy()
    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap="Set2")
    if epoch is not None and loss is not None:
        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)
    plt.show()

"""# Lista de Adjacencia dos Exercicios (Modificado)"""

# Importando defaultdict da biblioteca collections para criar dicionários com valores padrão
from collections import defaultdict

# Definindo a classe ListaAdjacencia
class ListaAdjacencia:
    # Construtor da classe
    def __init__(self, n_vertices):
        # Inicializando o dicionário que representa o grafo
        self.grafo = defaultdict(list)
        #Inicializando lista com as arestas em sua forma bruta
        self.grafo_deep_learning = []

        self.num_vertices = n_vertices
        # Preenchendo o grafo com listas vazias para cada vértice
        for i in range(n_vertices):
            self.grafo[i] = []

    def num_vertices(self):
      return self.n_vertices
    # Método para adicionar uma aresta ao grafo
    def adicionar_aresta(self, u, v):
        # Adicionando v à lista de vizinhos de u
        self.grafo[u].append(v)

        # Adicionando u à lista de vizinhos de v (para tornar o grafo não-direcionado)
        self.grafo[v].append(u)

        #Adicionando arestas na lista de grafos
        self.grafo_deep_learning.append([u,v])

    # Método para exibir o grafo
    def exibir_grafo(self):
        # Iterando sobre todos os vértices e seus vizinhos
        for vertice, vizinhos in self.grafo.items():
            # Imprimindo os vértices e seus vizinhos
            print(f"Vértice {vertice}: {vizinhos}")

    # Método para identificar loops no grafo
    def identificar_loops(self):
        # Iterando sobre todos os vértices e seus vizinhos
        for vertice, vizinhos in self.grafo.items():
            # Verificando se o vértice está em sua própria lista de vizinhos (loop)
            if vertice in vizinhos:
                print(f"Loop encontrado no vértice {vertice}")
                return True
        print("Nenhum loop encontrado")
        return False

    # Método para identificar arestas paralelas
    def identificar_arestas_paralelas(self):
        # Iterando sobre todos os vértices e seus vizinhos
        for vertice, vizinhos in self.grafo.items():
            # Verificando se há vizinhos repetidos (arestas paralelas)
            if len(vizinhos) != len(set(vizinhos)):
                print(f"Arestas paralelas encontradas no vértice {vertice}")
                return True
        print("Nenhuma aresta paralela encontrada")
        return False

    # Método para calcular o grau de cada vértice
    def calcular_graus(self):
        # Iterando sobre todos os vértices e seus vizinhos
        for vertice, vizinhos in self.grafo.items():
            # O grau é o número de vizinhos
            print(f"O grau do vértice {vertice} é {len(vizinhos)}")

    # Método para detectar vértices isolados
    def detectar_vertices_isolados(self):
        # Iterando sobre todos os vértices e seus vizinhos
        for vertice, vizinhos in self.grafo.items():
            # Se a lista de vizinhos é vazia, então o vértice é isolado
            if len(vizinhos) == 0:
                print(f"Vértice isolado encontrado: {vertice}")
                return True
        print("Nenhum vértice isolado encontrado")
        return False
    def retornar_grafo_deep_learning(self):
      return self.grafo_deep_learning

# Testando a classe com um exemplo
lista_adj = ListaAdjacencia(6)
lista_adj.adicionar_aresta(0, 1)
lista_adj.adicionar_aresta(0, 4)
lista_adj.adicionar_aresta(1, 3)
lista_adj.adicionar_aresta(3, 4)
lista_adj.adicionar_aresta(3, 2)
lista_adj.adicionar_aresta(2, 2)  # Loop
lista_adj.adicionar_aresta(3, 3)  # Loop
lista_adj.adicionar_aresta(1, 3)  # Aresta paralela

# Exibindo o grafo
print("Grafo:")
lista_adj.exibir_grafo()

# Identificando loops
print("\nIdentificando loops:")
lista_adj.identificar_loops()

# Identificando arestas paralelas
print("\nIdentificando arestas paralelas:")
lista_adj.identificar_arestas_paralelas()

# Calculando graus
print("\nCalculando graus:")
lista_adj.calcular_graus()

# Detectando vértices isolados
print("\nDetectando vértices isolados:")
lista_adj.detectar_vertices_isolados()

"""# O codigo abaixo vai converter os dados do grafo que foi montado acima para tensores do PyTorch"""

#Convertendo os dados do grafo em tensores e definindo os nos de treinamento
from torch_geometric.data import Data
from torch_geometric.utils import to_networkx
import random

edge_index = torch.tensor(lista_adj.retornar_grafo_deep_learning(), dtype=torch.long)
x = torch.randn(lista_adj.num_vertices, 1)
classificacao = []
for i in range(lista_adj.num_vertices):
  classificacao.append(random.randint(0,2))

data = Data(x=x, edge_index=edge_index.t().contiguous(), y=torch.LongTensor(classificacao))

#Iniciando todas as mascaras como False
num_nodes = data.num_nodes
train_mask = torch.zeros(num_nodes, dtype=torch.bool)
val_mask = torch.zeros(num_nodes, dtype=torch.bool)
test_mask = torch.zeros(num_nodes, dtype=torch.bool)

#Dividindo os nos para treinamento validação e teste
train_nodes = int(num_nodes * 0.7)
val_nodes = int(num_nodes * 0.15)

#Definindo aleatoriamente os índices para treinamento, validação e teste
all_indices = torch.randperm(num_nodes)
train_indices = all_indices[:train_nodes]
val_indices = all_indices[train_nodes:train_nodes+val_nodes]
test_indices = all_indices[train_nodes+val_nodes:]

#Atribuindo a mascara de valor booleano aos indices
train_mask[train_indices] = True
val_mask[val_indices] = True
test_mask[test_indices] = True

#Atribuindo o valor dos tensores locais para o Data
data.train_mask = train_mask
data.val_mask = val_mask
data.test_mask = test_mask

# Código para visualizar o grafo
G = to_networkx(data, to_undirected=True)
visualize_graph(G, color=data.y)

print('==============================================================')

# Propriedades do grafo para a validação do que esta codigo acima
print(f'Numero de nos: {data.num_nodes}')
print(f'Numero de arestas: {data.num_edges}')
print(f'Média de nos: {data.num_edges / data.num_nodes:.2f}')
print(f'Possui nós isolados: {data.has_isolated_nodes()}')
print(f'Possui loops: {data.has_self_loops()}')
print(f'É nao direcionado: {data.is_undirected()}')

print(f'Numero de nos treinados: {data.train_mask.sum()}')
print(f'Nós de treinamento porcentagem: {int(data.train_mask.sum()) / data.num_nodes:.2f}')

#Importando a classe Dataset para criar um dataset customizado
from torch_geometric.data import Dataset

class CustomDataset(Dataset):
    def __init__(self, data_list, root, transform=None, pre_transform=None):
        super(CustomDataset, self).__init__(root, transform, pre_transform)
        self.data_list = data_list

    def len(self):
        return len(self.data_list)

    def get(self, idx):
        return self.data_list[idx]

    def process(self):
        pass

    @property
    def processed_file_names(self):
        return ['data.pt']

dataset = CustomDataset([data], root='./tmp')

from torch.nn import Linear
from torch_geometric.nn import GCNConv


class GCN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        torch.manual_seed(1234)
        print(dataset.num_features)
        self.conv1 = GCNConv(dataset.num_features, 4)
        self.conv2 = GCNConv(4, 4)
        self.conv3 = GCNConv(4, 2)
        self.classifier = Linear(2, dataset.num_classes)

    def forward(self, x, edge_index):
        h = self.conv1(x, edge_index)
        h = h.tanh()
        h = self.conv2(h, edge_index)
        h = h.tanh()
        h = self.conv3(h, edge_index)
        h = h.tanh()

        # Apply a final (linear) classifier.
        out = self.classifier(h)

        return out, h

model = GCN()
print(model)

import time
from IPython.display import Javascript  # Restrict height of output cell.
display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})'''))

model = GCN()
criterion = torch.nn.CrossEntropyLoss()  # Definindo criterio de loss baseado na Função de crossEntropy
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.

def train(data):
    optimizer.zero_grad()  # Clear gradients.
    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.
    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.
    loss.backward()  # Derivando gradients.
    optimizer.step()  # Atualoizando parameters based on gradients.
    return loss, h

for epoch in range(341):
    loss, h = train(data)
    if epoch % 10 == 0:
        visualize_embedding(h, color=data.y, epoch=epoch, loss=loss)
        time.sleep(0.3)